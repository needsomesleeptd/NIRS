\chapter{Технологический раздел}

\section{Средства реализации}


\subsection{Используемые библиотеки}

\subsubsection{OpenCV}

OpenCV (Библиотека компьютерного зрения с открытым исходным кодом) - это библиотека программного обеспечения для компьютерного зрения и машинного обучения с открытым исходным кодом.

Библиотека содержит более 2500 оптимизированных алгоритмов, которые включают в себя полный набор как классических, так и самых современных алгоритмов компьютерного зрения и машинного обучения. Эти алгоритмы могут быть использованы для обнаружения и распознавания лиц, идентификации объектов, классификации действий человека в видео, отслеживания движений камеры, отслеживания движущихся объектов, поиска похожих изображений из база данных изображений,  распознавание пейзажа и т.~д.~\cite{about_openCV}.

Данная библиотека реализуют следующий функционал:
\begin{enumerate}
	\item поиск по шаблону (англ. template matching), данная функция позволяет 
	находить на изображении большего размера шаблон меньшего размера и выделять его, данная функция упростит поиск геометрических примитивов на изображении  ~\cite{pattern_matching};
	\item классификация  изображений из модуля глубоких нейронных сетей (англ. dense neural networks module) позволит разбивать изображения на необходимые подклассы~\cite{DL_openCV}.
	
	\item Благодаря оптическому распознаванию текста (англ. optical character recognition) возможно определение местоположения и получение информации о содержании текста~\cite{OCR_openCV}.
\end{enumerate}


\subsection{YOLO}

Популярная модель обнаружения объектов и сегментации изображений YOLO (You Only Look Once) была разработана Джозефом Редмоном и Али Фархади из Вашингтонского университета. YOLOv8, использующаяся в данной работе является эволюцией серии моделей YOLO \cite{YOLOv8}.
\begin{enumerate}
\item Модель YOLOv2, выпущенная в 2016 г., была усовершенствована за счет использования пакетной нормализации, якорных блоков и размерных кластеров.
\item YOLOv3, выпущенная в 2018 году, позволила еще больше повысить производительность модели за счет использования более эффективной опорной сети, множества якорей и объединения пространственных пирамид.
\item YOLOv4, выпущенная в 2020 году, обзавелась такими инновациями, как увеличение данных Mosaic, новая головка обнаружения без якорей и новая функция потерь.
\item YOLOv5 позволила еще больше повысить производительность модели, в этой версии быди добавлены такие новые возможности, как оптимизация гиперпараметров, интегрированное отслеживание экспериментов.
\item YOLOv6 была открыта компанией Meituan в 2022 году и используется во многих автономных роботах-доставщиках компании.
\item В YOLOv7 добавлены дополнительные задачи, такие как оценка позы по набору данных COCO keypoints.
\item YOLOv8 - это последняя версия YOLO от Ultralytics. Являясь передовой, современной (SOTA) моделью, YOLOv8 опирается на успех предыдущих версий, представляя новые возможности и улучшения для повышения производительности, гибкости и эффективности. YOLOv8 поддерживает полный спектр задач искусственного интеллекта, включая обнаружение, сегментацию, оценку положения, отслеживание и классификацию. Такая универсальность позволяет пользователям использовать возможности YOLOv8 в различных приложениях и областях.
\end{enumerate}


Для решения задачи детекции изображений также существуют альтернативные модели \cite{object_detection_models}: GroundingDINO, Faster R-CNN.

GroundingDINO --- модель, использующая трансформеры  и двухшаговый подход, заключающийся в извлечении визуальных и текстовых представлений, а затем выравнивании этих представлений.

Faster R-CNN --- редставляет собой метод обнаружения объектов, объединяющий конвейер из двух основных компонентов: сети глубокого обучения для извлечения признаков и регионального генератора для предложения областей, предположительно содержащих объекты.

\subsection{Метрики}
Для оценки успешности работы модели были рассмотрены метрики:
\begin{enumerate}
	\item средняя усредненная точность (англ. mean average precision, сокращенно mAP);
	\item точность (англ. precision);
	\item отзыв (англ. recall).
\end{enumerate}

При решении задачи детекции, необходимо  также решить задачу классификации, для оценки успешности классификации изображений была использованы метрики precision  
и recall, для оценки точности выделения нужных объектов используется метрика mAP. 

\subsection{Точность}
\textbf{Точность} для данного класса в многоклассовой классификации --- это доля экземпляров, правильно классифицированных как принадлежащие к определенному классу, из всех экземпляров, которые модель предсказала как принадлежащие к этому классу \cite{class_metrics}.

\subsection{Отзыв}
\textbf{Отзыв} в многоклассовой классификации - это доля экземпляров в классе, которые модель правильно классифицировала, из всех экземпляров в этом классе \cite{class_metrics}..

\subsection{Усреднение}
Так как классификация многоклассовая, в случае yolov8 приведенные выше метрики рассчитываются отдельно для каждого класса, после усредняются, используя макроусреднение (англ. macro-averaging) \cite{YOLOv8}. При использовании данного метода вычисляется среднее метрик по каждому классу \cite{class_metrics}.Пример расчета данной метрики приведен на картинке \ref{img:macro-average}.

\includeimage
{macro-average} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.9\textwidth} % Ширина рисунка
{Пример расчета precision и recall с использование macro-averaging} % Подпись рисунка



\subsection{Средняя усредненная точность}
При решении задач детекции, необходимо заключить требуемый объект в ограничивающей рамке (англ. bounding box).
Для поиска требуемого значения вводится еще одна метрика пересечение перед объединением (англ. intersection over union сокращенно iou),
для ее подсчета необходимо разделить площадь пересечения (англ. area of overlap) предсказанного и  размеченных bounding box  на площадь их объеденения (англ. area of union)
пример расчета данной метрики представлен на картинке \ref{img:mAP}.


\includeimage
{mAP} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.9\textwidth} % Ширина рисунка
{Расчет mAP} % Подпись рисунка


После введения iou вводится нижний <<порог>>  значений iou, его значение может быть любым. В случае, 
если предсказанный bounding box, имеет iou с размеченным меньший чем <<порог>>, то объект относится  к неверно определенным значениям (false positive), 
иначе относится к верно определенным значениям (true positive), стоит также уточнить, что на одном изображении может быть предсказано несколько
bounding box, при этом предсказанные bounding box сортируются по <<уверенности>> модели в результате.
После разделения изображений на false positive  и true positive, вычисляются описанные ранее метрики precision  и recall.
После чего усредненная точность получается подсчетом площади под кривой precision-recall. Например в примере на картинке \ref{img:AP_calculation}, метрика
среднего значения $AP$ будет расчитана по формуле (\ref{eq:AP}) \cite{mAP}.

\begin{equation}
	\label{eq:AP}
	AP = \frac{1}{11}\sum_{Recall_i}Precision(Recall_i) = \frac{1}{11} \cdot (1 \cdot 6) + (0 \cdot 5) = 0.545
\end{equation}


\includeimage
{AP_calculation} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.9\textwidth} % Ширина рисунка
{Примера расчета AP} % Подпись рисунка

После получения метрики $AP$ для каждого класса, значения $AP$ усредняются, давая требуемое значение $mAP$.