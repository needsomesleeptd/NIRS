\chapter{Технологический раздел}

\section{Средства реализации}


\subsection{Используемые библиотеки}

\subsubsection{OpenCV}

OpenCV --- это библиотека программного обеспечения для компьютерного зрения и машинного обучения с открытым исходным кодом.

Библиотека содержит более 2500 оптимизированных алгоритмов, которые включают в себя полный набор как классических, так и самых современных алгоритмов компьютерного зрения и машинного обучения. Эти алгоритмы могут быть использованы для обнаружения и распознавания лиц, идентификации объектов, классификации действий человека в видео, отслеживания движений камеры, отслеживания движущихся объектов, поиска похожих изображений из база данных изображений,  распознавание пейзажа и т.~д.~\cite{about_openCV}.

Данная библиотека реализуют следующий функционал:
\begin{enumerate}
	\item поиск по шаблону (англ. template matching), данная функция позволяет 
	находить на изображении большего размера шаблон меньшего размера и выделять его, данная функция упростит поиск геометрических примитивов на изображении  ~\cite{pattern_matching};
	\item классификация  изображений из модуля глубоких нейронных сетей (англ. dense neural networks module) позволит разбивать изображения на необходимые подклассы~\cite{DL_openCV}.
	
	\item Благодаря оптическому распознаванию текста (англ. optical character recognition) возможно определение местоположения и получение информации о содержании текста~\cite{OCR_openCV}.
\end{enumerate}


\subsection{YOLO}

Популярная модель обнаружения объектов и сегментации изображений YOLO (англ. You Only Look Once) была разработана Джозефом Редмоном и Али Фархади из Вашингтонского университета. YOLOv8, использующаяся в данной работе является эволюцией серии моделей YOLO~\cite{YOLOv8}.
\begin{enumerate}
\item Модель YOLOv2, выпущенная в 2016 г., была усовершенствована за счет использования пакетной нормализации, якорных блоков и размерных кластеров~\cite{yolo_v2}.
\item YOLOv3, выпущенная в 2018 году, позволила еще больше повысить производительность модели за счет использования более эффективной опорной сети, множества якорей и объединения пространственных пирамид~\cite{yolo_v3}.
\item YOLOv4, выпущенная в 2020 году, обзавелась такими инновациями, как увеличение данных Mosaic, и <<голова>>, работающая без якорей и новая функция потерь~\cite{yolo_v4}.
\item YOLOv5 позволила еще больше повысить производительность модели, в этой версии быди добавлены такие новые возможности, как оптимизация гиперпараметров, интегрированное отслеживание обучения~\cite{yolo_v5}.
\item YOLOv6 была открыта компанией Meituan в 2022 году и используется во многих автономных роботах-доставщиках компании~\cite{yolo_v6}.
\item В YOLOv7 добавлены дополнительные задачи, такие как оценка позы по набору данных COCO keypoints~\cite{yolo_v7}.
\item YOLOv8 --- это последняя версия YOLO на сегодняшний день от Ultralytics, поддерживающая обнаружение, сегментацию, оценку положения, отслеживание и классификацию~\cite{YOLOv8}.
\end{enumerate}


Для решения задачи детекции изображений также существуют альтернативные модели \cite{object_detection_models}: GroundingDINO, Faster R-CNN.

GroundingDINO --- модель, использующая трансформеры  и двухшаговый подход, заключающийся в извлечении визуальных и текстовых представлений, а затем выравнивании этих представлений.

Faster R-CNN --- представляет собой метод обнаружения объектов, объединяющий конвейер из двух основных компонентов: сети глубокого обучения для извлечения признаков и регионального генератора для предложения областей, предположительно содержащих объекты.

\section{Метрики}
Для оценки успешности работы модели были рассмотрены метрики:
\begin{enumerate}
	\item средняя усредненная точность (англ. mean average precision, сокращенно mAP);
	\item точность (англ. precision);
	\item отзыв (англ. recall).
\end{enumerate}

При решении задачи детекции, необходимо  также решить задачу классификации, для оценки успешности классификации изображений была использованы метрики precision  
и recall, для оценки точности выделения нужных объектов используется метрика mAP. 

\subsection{Точность}
\textbf{Точность} для данного класса в многоклассовой классификации --- это доля экземпляров, правильно классифицированных как принадлежащие к определенному классу, из всех экземпляров, которые модель предсказала как принадлежащие к этому классу \cite{class_metrics}.

\subsection{Отзыв}
\textbf{Отзыв} в многоклассовой классификации --- это доля экземпляров в классе, которые модель правильно классифицировала, из всех экземпляров в этом классе \cite{class_metrics}.

\subsection{Усреднение}
Так как классификация многоклассовая, в случае YOLOv8 приведенные выше метрики рассчитываются отдельно для каждого класса, после усредняются, используя макроусреднение (англ. macro-averaging) \cite{YOLOv8}. При использовании данного метода вычисляется среднее метрик по каждому классу \cite{class_metrics}. Данная метрика рассчитывается согласно следующим формулам:

\begin{equation}
\label{eq:precision}
Precision = \frac{Precision_{Class A} + Precision_{Class B} + ... + Precision_{Class N}}{N}
\end{equation}

\begin{equation}
\label{eq:recall}
Recall = \frac{Recall_{Class A} + Recall_{Class B} + ... + Recall_{Class N}}{N}
\end{equation}

%\includeimage
%{macro-average} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
%{f} % Обтекание (без обтекания)
%{H} % Положение рисунка (см. figure из пакета float)
%{0.9\textwidth} % Ширина рисунка
%{Пример расчета precision и recall с использование macro-averaging} % Подпись рисунка



\subsection{Средняя усредненная точность}
При решении задач детекции, необходимо заключить требуемый объект в ограничивающую рамку (англ. bounding box).
Для поиска требуемого значения вводится еще одна метрика <<пересечение перед объединением>> (англ. intersection over union, сокращенно iou),
для ее подсчета необходимо разделить площадь пересечения (англ. area of overlap), предсказанных и  размеченных ограничивающих рамок на площадь их объеденения (англ. area of union):
\begin{equation}
Intersection\ over\ Union\ (iou) = \frac{Area\ of\ Overlap}{Area\ of\ Union}.
\end{equation}

После введения <<пересечения перед объединением>> (англ. iou) вводится нижний <<порог>>  значений этой метрики, значение данного порога может быть любым. В случае, 
если предсказанная ограничивающая рамка имеет значение <<пересечения перед объединением>> с размеченной рамкой меньше, чем <<порог>>, то объект относится  к неверно определенным значениям (англ. false positive), 
иначе относится к верно определенным значениям (англ. true positive), стоит также уточнить, что на одном изображении может быть предсказано несколько объектов, при этом предсказанные ограничивающие рамки сортируются по <<уверенности>> модели для данного результата.
После разделения изображений на неверно определенные и верно определенные значения, вычисляются описанные ранее метрики точность и отзыв.
После чего усредненная точность вычисляется подсчетом площади под кривой точность-отзыв. Например, на рисунке \ref{img:AP_calculation} метрика
среднего значения (англ. average precision, сокращенно $AP$) будет рассчитана по формуле~(\ref{eq:AP})~\cite{mAP}.

\begin{equation}
	\label{eq:AP}
	AP = \frac{1}{11}\sum_{Recall_i}Precision(Recall_i) = \frac{1}{11} \cdot (1 \cdot 6) + (0 \cdot 5) = 0.545
\end{equation}


\includeimage
{AP_calculation} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.9\textwidth} % Ширина рисунка
{Примера расчета AP} % Подпись рисунка

После получения метрики $AP$ для каждого класса, значения $AP$ усредняются, результатом усреднения  $AP$ по всем классам является требуемое значение $mAP$.


\section{Этапы обучения модели}
Процесс обучения модели состоит из нескольких этапов \cite{learning}:
\begin{enumerate}
	\item разметка данных;
	\item предобработка данных;
	\item обучение модели;
	\item анализ результатов обучения модели;
\end{enumerate}

\subsubsection{Разметка данных}
Перед запуском процесса обучения необходимо соотнести данные с требуемыми значениями с рамках поставленной задачи. В случае задачи классификации
необходимо сопоставить каждый объект одному из классов. На данном этапе необходимо собрать  максимальное количество данных для наиболее эффективного обучения модели \cite{learning}.

\subsubsection{Предобработка данных}
На данном этапе необходимо привести данные в соответствующий для модели формат. Также производится анализ количества классов, и собранный набор данных
разделяется на тренировочную выборку и валидационную выборку. На тренировочной выборке модель будет <<обучаться>>, с помощью валидационной выборки 
можно оценить точность работы модели. Также на данном этапе определяются метрики для оценки качества модели \cite{learning}.

\subsubsection{Обучение модели}
На тренировочной выборке запускается процесс обучения модели, с определенными гиперпараметрами. Модели обучаются несколько эпох, каждая эпоха --- полный 
<<проход>> модели по тренировочной выборке в процессе обучения \cite{epoch}.

\subsubsection{Анализ результатов обучения модели}
После окончания процесса обучения, рассматриваются значения  выделенных метрик и делаются выводы  о точности работы модели, принимается
решение о выборе иной модели или других значений гиперпараметров \cite{learning}.

\section{Использование Astra Linux}
Astra Linux позволяет использовать библиотеки глубокого обучения, такие как <<TensorFlow>> и <<Keras>> \cite{astra_linux}. Данные библиотеки позволяют
решать задачу детекции изображений с помощью модели YOLOv8, что дает возможность реализовать обучение на данной операционной системе~\cite{keras_yolov8}.











